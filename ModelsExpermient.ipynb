{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tlfs_MqDQgW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Install Dependencies"
      ],
      "metadata": {
        "id": "eAmFsnxMTGNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "id": "iWPIAahJE6Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0770f4a6-b267-4ee9-f5fc-9a9a8484f5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras"
      ],
      "metadata": {
        "id": "rhdmrheSNk6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1d5e55-b506-42a9-de4d-089bf5679774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Set Directory Path"
      ],
      "metadata": {
        "id": "1iS0ovWyGwee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Phxtcz6dE8_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "146a62a0-38ac-4a60-844a-a27812a5b092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Full path of the data to train the model\n",
        "_DATA = '/content/drive/MyDrive/Data/delaney-processed.csv'"
      ],
      "metadata": {
        "id": "xKT0NTWoJPTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explore Data"
      ],
      "metadata": {
        "id": "OO-KBoc0n-ZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(_DATA)"
      ],
      "metadata": {
        "id": "TYdY_yc7nOvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "4KDthg6EpwyY",
        "outputId": "69162a91-df0c-4364-95e7-c669ad101f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Compound ID  ESOL predicted log solubility in mols per litre  \\\n",
              "0   Amigdalin                                           -0.974   \n",
              "1    Fenfuram                                           -2.885   \n",
              "2      citral                                           -2.579   \n",
              "3      Picene                                           -6.618   \n",
              "4   Thiophene                                           -2.232   \n",
              "\n",
              "   Minimum Degree  Molecular Weight  Number of H-Bond Donors  Number of Rings  \\\n",
              "0               1           457.432                        7                3   \n",
              "1               1           201.225                        1                2   \n",
              "2               1           152.237                        0                0   \n",
              "3               2           278.354                        0                5   \n",
              "4               2            84.143                        0                1   \n",
              "\n",
              "   Number of Rotatable Bonds  Polar Surface Area  \\\n",
              "0                          7              202.32   \n",
              "1                          2               42.24   \n",
              "2                          4               17.07   \n",
              "3                          0                0.00   \n",
              "4                          0                0.00   \n",
              "\n",
              "   measured log solubility in mols per litre  \\\n",
              "0                                      -0.77   \n",
              "1                                      -3.30   \n",
              "2                                      -2.06   \n",
              "3                                      -7.87   \n",
              "4                                      -1.33   \n",
              "\n",
              "                                              smiles  \n",
              "0  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...  \n",
              "1                             Cc1occc1C(=O)Nc2ccccc2  \n",
              "2                               CC(C)=CCCC(C)=CC(=O)  \n",
              "3                 c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43  \n",
              "4                                            c1ccsc1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c46b9a03-c32f-4047-80a8-fac73e2cd679\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Compound ID</th>\n",
              "      <th>ESOL predicted log solubility in mols per litre</th>\n",
              "      <th>Minimum Degree</th>\n",
              "      <th>Molecular Weight</th>\n",
              "      <th>Number of H-Bond Donors</th>\n",
              "      <th>Number of Rings</th>\n",
              "      <th>Number of Rotatable Bonds</th>\n",
              "      <th>Polar Surface Area</th>\n",
              "      <th>measured log solubility in mols per litre</th>\n",
              "      <th>smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Amigdalin</td>\n",
              "      <td>-0.974</td>\n",
              "      <td>1</td>\n",
              "      <td>457.432</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>202.32</td>\n",
              "      <td>-0.77</td>\n",
              "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fenfuram</td>\n",
              "      <td>-2.885</td>\n",
              "      <td>1</td>\n",
              "      <td>201.225</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>42.24</td>\n",
              "      <td>-3.30</td>\n",
              "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>citral</td>\n",
              "      <td>-2.579</td>\n",
              "      <td>1</td>\n",
              "      <td>152.237</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>17.07</td>\n",
              "      <td>-2.06</td>\n",
              "      <td>CC(C)=CCCC(C)=CC(=O)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Picene</td>\n",
              "      <td>-6.618</td>\n",
              "      <td>2</td>\n",
              "      <td>278.354</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-7.87</td>\n",
              "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thiophene</td>\n",
              "      <td>-2.232</td>\n",
              "      <td>2</td>\n",
              "      <td>84.143</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.33</td>\n",
              "      <td>c1ccsc1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c46b9a03-c32f-4047-80a8-fac73e2cd679')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c46b9a03-c32f-4047-80a8-fac73e2cd679 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c46b9a03-c32f-4047-80a8-fac73e2cd679');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7b95206b-0e33-4929-b6e9-0502e3bd80bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b95206b-0e33-4929-b6e9-0502e3bd80bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7b95206b-0e33-4929-b6e9-0502e3bd80bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1128,\n  \"fields\": [\n    {\n      \"column\": \"Compound ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1128,\n        \"samples\": [\n          \"cis-2-Pentene\",\n          \"5-(3-Methyl-2-butenyl)-5-ethylbarbital\",\n          \"Terbacil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ESOL predicted log solubility in mols per litre\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6832198243710366,\n        \"min\": -9.702,\n        \"max\": 1.091,\n        \"num_unique_values\": 920,\n        \"samples\": [\n          -3.184,\n          -4.835,\n          -1.132\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Minimum Degree\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Molecular Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 102.73807720680973,\n        \"min\": 16.043,\n        \"max\": 780.9490000000001,\n        \"num_unique_values\": 806,\n        \"samples\": [\n          527.4140000000002,\n          168.10799999999995,\n          393.85400000000016\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of H-Bond Donors\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of Rings\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          7,\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of Rotatable Bonds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          7,\n          3,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polar Surface Area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.38359265570078,\n        \"min\": 0.0,\n        \"max\": 268.67999999999995,\n        \"num_unique_values\": 283,\n        \"samples\": [\n          58.2,\n          100.45,\n          40.620000000000005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"measured log solubility in mols per litre\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.096441210089345,\n        \"min\": -11.6,\n        \"max\": 1.58,\n        \"num_unique_values\": 734,\n        \"samples\": [\n          -2.13,\n          -1.64,\n          -0.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smiles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1128,\n        \"samples\": [\n          \"CC/C=C\\\\C\",\n          \"O=C1NC(=O)NC(=O)C1(CC)CC=C(C)C\",\n          \"Cc1[nH]c(=O)n(c(=O)c1Cl)C(C)(C)C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model(s)"
      ],
      "metadata": {
        "id": "cEmpFd7JG-bc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1st Model: ANN, RNN, LSTM and Reinforcement"
      ],
      "metadata": {
        "id": "Jz_9VsDNiYP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from keras.layers import Input, Dense, Concatenate, Lambda, Reshape, GRU, LSTM\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import mean_squared_error\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Flatten\n",
        "import random\n",
        "\n",
        "# Path and filename to save the model\n",
        "MODEL_DIRECTORY = 'saved_model'\n",
        "MODEL_FILENAME = 'ann_model_1.h5'\n",
        "MODEL_PATH = os.path.join(MODEL_DIRECTORY, MODEL_FILENAME)\n",
        "\n",
        "df = pd.read_csv(_DATA)\n",
        "df = df.rename(columns={'Compound ID': 'id', 'ESOL predicted log solubility in mols per litre': 'binding_affinity'})\n",
        "df = df[['id', 'smiles', 'binding_affinity']]\n",
        "df = df.dropna()\n",
        "\n",
        "X = [Chem.MolFromSmiles(smiles) for smiles in df['smiles']]\n",
        "\n",
        "X = np.array([list(AllChem.GetMorganFingerprintAsBitVect(mol, 2)) for mol in X])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df['binding_affinity'], test_size=0.2)\n",
        "\n",
        "# input_shape is the length of the fingerprint vector\n",
        "input_shape = (X.shape[1],)\n",
        "\n",
        "# 1: ANN:\n",
        "# Create input layer with specified shape\n",
        "inputs = Input(shape=input_shape, dtype=tf.int32)\n",
        "\n",
        "# Add backpropagation layer\n",
        "# Convert the int32 tensor to float32\n",
        "backpropagation = Lambda(lambda x: tf.cast(x, tf.float32))(inputs)\n",
        "\n",
        "x = Dense(512, activation='relu')(inputs)\n",
        "x = Concatenate()([x, backpropagation]) # Concatenate the two tensors\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "\n",
        "# Add flatten layer\n",
        "flatten = Flatten()(x)\n",
        "\n",
        "# Add reshape layer(s)\n",
        "reshape = Reshape((1, 64))(flatten)\n",
        "\n",
        "\n",
        "# 2: RNN:\n",
        "# Add RNN layer(s)\n",
        "rnn1 = GRU(128, input_shape=(None, 64), batch_size=1)(reshape)\n",
        "rnn2 = GRU(128, input_shape=(None, 64), batch_size=1)(reshape)\n",
        "rnn3 = GRU(128, input_shape=(None, 64), batch_size=1)(reshape)\n",
        "rnn_layers = [rnn1, rnn2, rnn3]\n",
        "\n",
        "# 3: LSTM:\n",
        "# Add LSTM layer(s)\n",
        "lstm1 = LSTM(128, input_shape=(None, 64), batch_size=1)(reshape)\n",
        "lstm2 = LSTM(128, input_shape=(None, 64), batch_size=1)(reshape)\n",
        "lstm3 = LSTM(128, input_shape=(None, 64), batch_size=1)(reshape)\n",
        "lstm_layers = [lstm1, lstm2, lstm3]\n",
        "\n",
        "# 4: Reinforcement:\n",
        "class EpsilonGreedyPolicy(object):\n",
        "    def __init__(self, epsilon):\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def __call__(self, state):\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.randint(0, 1)\n",
        "        else:\n",
        "            return np.argmax(state)\n",
        "\n",
        "class ActorCritic(object):\n",
        "    def __init__(self, policy, critic):\n",
        "        self.policy = policy\n",
        "        self.critic = critic\n",
        "\n",
        "    def __call__(self, state):\n",
        "        return self.policy(state), self.critic(state)\n",
        "\n",
        "state = np.array([1, 2, 3])\n",
        "\n",
        "policy = EpsilonGreedyPolicy(epsilon=0.1)\n",
        "critic = Lambda(lambda x: x)\n",
        "agent = ActorCritic(policy, critic)\n",
        "\n",
        "action, value = agent(state)\n",
        "\n",
        "reinforcement_layers = [policy, critic]\n",
        "\n",
        "\n",
        "# Combine all layers (RNN, LSTM, and reinforcement layers)\n",
        "combined_layers = rnn_layers + lstm_layers\n",
        "combined_model = Concatenate()(combined_layers)\n",
        "\n",
        "# Add output layer with single unit and linear\n",
        "outputs = Dense(1, activation='linear')(combined_model)\n",
        "\n",
        "# Create model with input and output layer\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss=mean_squared_error)\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1)\n",
        "\n",
        "print(f'Saving trained model to {MODEL_PATH}...')\n",
        "model.save(MODEL_PATH)\n",
        "\n",
        "print(f'Loading trained model from {MODEL_PATH}...')\n",
        "model = load_model(MODEL_PATH)\n",
        "\n",
        "smiles = ['COC1=C(C=C(C=C1)C(=O)O)O']\n",
        "\n",
        "X_new = np.array(tf.stack([list(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smi), 2)) for smi in smiles]))\n",
        "\n",
        "y_pred = model.predict(X_new)\n",
        "\n",
        "print('Predicted binding affinity:', y_pred[0][0])"
      ],
      "metadata": {
        "id": "t3_xCnUIDW0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8de467-28e2-4731-b2a2-990a2d134c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - 15s 14ms/step - loss: 3.8432\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.8393\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.5540\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.3307\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.2051\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1882\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.1612\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1683\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1108\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0849\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0943\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0900\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0816\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1005\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0839\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0793\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0876\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0986\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1068\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1117\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1355\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0919\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0796\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.1187\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.0850\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 0.1315\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.1023\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0758\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0625\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0637\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.0687\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.1278\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0919\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0796\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0967\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0832\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.0641\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0659\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0667\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0661\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0591\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0581\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0704\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0703\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0601\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0955\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0664\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0597\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0719\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0680\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0865\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0677\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0617\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0674\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0600\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0650\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0797\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0727\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0767\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.1024\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.0791\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.0673\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0778\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.0705\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0743\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0602\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0638\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0679\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0667\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0643\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0605\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0555\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0687\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0586\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0496\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0739\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0707\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0677\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0579\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0641\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0690\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0775\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0646\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0581\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0587\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0644\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0711\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0613\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0625\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 0.0599\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.0628\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 1s 48ms/step - loss: 0.0673\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 0.0729\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 1s 34ms/step - loss: 0.0589\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0565\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0592\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0687\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.0631\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0511\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0566\n",
            "Saving trained model to saved_model/ann_model_1.h5...\n",
            "Loading trained model from saved_model/ann_model_1.h5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Predicted binding affinity: -2.5836887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2nd Model: Conditional Variational Autoencoder"
      ],
      "metadata": {
        "id": "bfQDBzMllINA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path and filename to save the model\n",
        "MODEL_DIRECTORY = 'saved_model'\n",
        "MODEL_FILENAME = 'cvae_model_1.h5'\n",
        "MODEL_PATH = os.path.join(MODEL_DIRECTORY, MODEL_FILENAME)\n",
        "\n",
        "# Define the desired output dimension for the CVAE model\n",
        "MODEL_CVAE_OUTPUT_DIM = 1\n",
        "\n",
        "df = pd.read_csv(_DATA)\n",
        "df = df.rename(columns={'Compound ID': 'id', 'ESOL predicted log solubility in mols per litre': 'binding_affinity'})\n",
        "df = df[['id', 'smiles', 'binding_affinity']]\n",
        "df = df.dropna()\n",
        "\n",
        "# Scale the target variable\n",
        "y_train_scaled = -(df['binding_affinity'] - df['binding_affinity'].min()) / (df['binding_affinity'].max() - df['binding_affinity'].min())\n",
        "\n",
        "X = [Chem.MolFromSmiles(smiles) for smiles in df['smiles']]\n",
        "X = np.array([list(AllChem.GetMorganFingerprintAsBitVect(mol, 2)) for mol in X])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_train_scaled, test_size=0.2)\n",
        "\n",
        "# Define input_shape and encoding_dim\n",
        "input_shape = (X.shape[1],)\n",
        "encoding_dim = 128\n",
        "num_classes = 1  # Number of classes, in this case, 1 for binding affinity\n",
        "\n",
        "# Create input layers for features and class labels\n",
        "input_features = Input(shape=input_shape)\n",
        "input_labels = Input(shape=(num_classes,))\n",
        "\n",
        "# Concatenate features and labels\n",
        "concatenated_input = Concatenate(axis=-1)([input_features, input_labels])\n",
        "\n",
        "# Add encoding layers\n",
        "h1 = Dense(512, activation='relu')(concatenated_input)\n",
        "h2 = Dense(256, activation='relu')(h1)\n",
        "h3 = Dense(128, activation='relu')(h2)\n",
        "z_mean = Dense(encoding_dim)(h3)\n",
        "z_log_var = Dense(encoding_dim)(h3)\n",
        "\n",
        "# Add sampling layer (e.g., using the reparameterization trick)\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = tf.keras.backend.shape(z_mean)[0]\n",
        "    dim = encoding_dim\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim), mean=0.0, stddev=1.0)\n",
        "    return z_mean + tf.keras.backend.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Name the Lambda layer explicitly\n",
        "z = Lambda(sampling, output_shape=(encoding_dim,), name='cvae_lambda_layer')([z_mean, z_log_var])\n",
        "\n",
        "# Define the decoder layers and output\n",
        "decoding_1 = Dense(128, activation='relu')\n",
        "decoding_2 = Dense(256, activation='relu')\n",
        "decoding_3 = Dense(512, activation='relu')\n",
        "decoding_4 = Dense(input_shape[0], activation='linear')  # Changed activation to 'linear' for continuous output\n",
        "\n",
        "# Connect the encoding and decoding layers to build the model\n",
        "decoder_input = Input(shape=(encoding_dim,))\n",
        "decoder_input_concatenated = Concatenate(axis=-1)([decoder_input, input_labels])\n",
        "decoder_layer1 = decoding_1(decoder_input_concatenated)\n",
        "decoder_layer2 = decoding_2(decoder_layer1)\n",
        "decoder_layer3 = decoding_3(decoder_layer2)\n",
        "decoder_output = decoding_4(decoder_layer3)\n",
        "\n",
        "decoder = Model([decoder_input, input_labels], decoder_output)\n",
        "\n",
        "outputs = decoder([z, input_labels])\n",
        "\n",
        "# Reverse the scaling during loss calculation\n",
        "reconstruction_loss = tf.keras.losses.mse(input_features, outputs) * (y_train.max() - y_train.min()) + y_train.min()\n",
        "kl_loss = -0.5 * tf.keras.backend.mean(1 + z_log_var - tf.keras.backend.square(z_mean) - tf.keras.backend.exp(z_log_var), axis=-1)\n",
        "cvae_loss = tf.keras.backend.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "# Compile the full CVAE model\n",
        "cvae = Model([input_features, input_labels], outputs)\n",
        "cvae.add_loss(cvae_loss)\n",
        "cvae.compile(optimizer=Adam(learning_rate=0.001))\n",
        "\n",
        "# Adjust the output dimension of the CVAE model\n",
        "# Modify the output layer to produce a single output\n",
        "# For example, change from Dense(2048, activation='linear') to Dense(1, activation='linear')\n",
        "input_layer_cvae = Input(shape=input_shape)  # Assuming you have input_shape_cvae defined elsewhere\n",
        "hidden_layer_cvae = Dense(512, activation='relu')(input_layer_cvae)\n",
        "# Adjusted output layer\n",
        "output_layer_cvae = Dense(MODEL_CVAE_OUTPUT_DIM, activation='linear')(hidden_layer_cvae)\n",
        "MODEL_CVAE = Model(inputs=input_layer_cvae, outputs=output_layer_cvae)\n",
        "MODEL_CVAE.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the CVAE model\n",
        "history = cvae.fit([X_train, y_train], batch_size=128, epochs=50, shuffle=True, validation_data=([X_test, y_test], None))\n",
        "\n",
        "# Save the trained model\n",
        "if not os.path.exists(MODEL_DIRECTORY):\n",
        "    os.makedirs(MODEL_DIRECTORY)\n",
        "\n",
        "# Save the trained model in the native Keras format\n",
        "cvae.save(MODEL_PATH)\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "# Make a prediction for a single molecule\n",
        "#smiles = 'CC1=NC(=C2C(=N1)C(=O)N(C(=S)N2C)C)N'\n",
        "smiles = 'COC1=C(C=C(C=C1)C(=O)O)O'\n",
        "mol = Chem.MolFromSmiles(smiles)\n",
        "fp = np.array(list(AllChem.GetMorganFingerprintAsBitVect(mol, 2)))\n",
        "fp = np.reshape(fp, (1, fp.shape[0]))\n",
        "\n",
        "# Prepare the labels (y) for prediction\n",
        "label = np.array([[0]])  # Adjust this based on your label format\n",
        "\n",
        "# Reverse the scaling for prediction\n",
        "prediction = loaded_model.predict([fp, label]) * (y_train.max() - y_train.min()) + y_train.min()\n",
        "\n",
        "# Print the predicted binding affinity\n",
        "print('Predicted binding affinity: ', prediction[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLFYXHj0h9gk",
        "outputId": "c1b03aad-e187-4320-b306-bc463b275ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 5s 224ms/step - loss: -0.9819 - val_loss: -0.9872\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 1s 69ms/step - loss: -0.9873 - val_loss: -0.9880\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: -0.9878 - val_loss: -0.9882\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 1s 70ms/step - loss: -0.9883 - val_loss: -0.9883\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 1s 68ms/step - loss: -0.9880 - val_loss: -0.9885\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: -0.9884 - val_loss: -0.9887\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 1s 73ms/step - loss: -0.9887 - val_loss: -0.9889\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: -0.9888 - val_loss: -0.9890\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 1s 70ms/step - loss: -0.9892 - val_loss: -0.9892\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: -0.9891 - val_loss: -0.9892\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 1s 72ms/step - loss: -0.9890 - val_loss: -0.9892\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: -0.9893 - val_loss: -0.9892\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 1s 72ms/step - loss: -0.9888 - val_loss: -0.9893\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 1s 70ms/step - loss: -0.9894 - val_loss: -0.9892\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 1s 65ms/step - loss: -0.9891 - val_loss: -0.9893\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 1s 66ms/step - loss: -0.9890 - val_loss: -0.9893\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 1s 70ms/step - loss: -0.9890 - val_loss: -0.9893\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 1s 70ms/step - loss: -0.9892 - val_loss: -0.9893\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 1s 70ms/step - loss: -0.9893 - val_loss: -0.9893\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 1s 102ms/step - loss: -0.9890 - val_loss: -0.9893\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 1s 101ms/step - loss: -0.9895 - val_loss: -0.9893\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 1s 97ms/step - loss: -0.9889 - val_loss: -0.9893\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 1s 105ms/step - loss: -0.9891 - val_loss: -0.9893\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -0.9888 - val_loss: -0.9893\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 1s 105ms/step - loss: -0.9892 - val_loss: -0.9893\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 1s 75ms/step - loss: -0.9892 - val_loss: -0.9893\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 1s 81ms/step - loss: -0.9894 - val_loss: -0.9893\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 1s 78ms/step - loss: -0.9893 - val_loss: -0.9893\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 1s 75ms/step - loss: -0.9894 - val_loss: -0.9893\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 1s 73ms/step - loss: -0.9894 - val_loss: -0.9893\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 1s 70ms/step - loss: -0.9893 - val_loss: -0.9893\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 1s 95ms/step - loss: -0.9892 - val_loss: -0.9893\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 1s 109ms/step - loss: -0.9890 - val_loss: -0.9893\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 1s 67ms/step - loss: -0.9889 - val_loss: -0.9893\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 1s 69ms/step - loss: -0.9891 - val_loss: -0.9893\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 1s 69ms/step - loss: -0.9890 - val_loss: -0.9893\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 1s 71ms/step - loss: -0.9894 - val_loss: -0.9893\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 1s 63ms/step - loss: -0.9890 - val_loss: -0.9893\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 1s 71ms/step - loss: -0.9892 - val_loss: -0.9893\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 1s 70ms/step - loss: -0.9895 - val_loss: -0.9893\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 1s 72ms/step - loss: -0.9896 - val_loss: -0.9893\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 1s 100ms/step - loss: -0.9894 - val_loss: -0.9893\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 1s 106ms/step - loss: -0.9895 - val_loss: -0.9893\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 1s 103ms/step - loss: -0.9893 - val_loss: -0.9893\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 1s 104ms/step - loss: -0.9895 - val_loss: -0.9893\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 1s 101ms/step - loss: -0.9891 - val_loss: -0.9893\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 1s 77ms/step - loss: -0.9891 - val_loss: -0.9893\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 1s 79ms/step - loss: -0.9893 - val_loss: -0.9893\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 1s 86ms/step - loss: -0.9894 - val_loss: -0.9893\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 1s 76ms/step - loss: -0.9892 - val_loss: -0.9893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 235ms/step\n",
            "Predicted binding affinity:  -0.99767375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3rd Model: Stacking Model"
      ],
      "metadata": {
        "id": "Oj69ei8_o_2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from keras.models import load_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(_DATA)\n",
        "df = df.rename(columns={'Compound ID': 'id', 'ESOL predicted log solubility in mols per litre': 'binding_affinity'})\n",
        "df = df[['id', 'smiles', 'binding_affinity']]\n",
        "df = df.dropna()\n",
        "\n",
        "# Extract features X and target variable y\n",
        "X = [Chem.MolFromSmiles(smiles) for smiles in df['smiles']]\n",
        "X = np.array([list(AllChem.GetMorganFingerprintAsBitVect(mol, 2)) for mol in X])\n",
        "y = df['binding_affinity']\n",
        "\n",
        "# Load models\n",
        "model_1 = load_model('saved_model/ann_model_1.h5')\n",
        "model_2 = load_model('saved_model/cvae_model_1.h5')\n",
        "\n",
        "# Generate placeholder labels for the entire dataset\n",
        "num_samples = len(X)\n",
        "placeholder_labels = np.zeros((num_samples, 1))  # Assuming one class label\n",
        "\n",
        "# Predictions for the entire dataset using both models\n",
        "y_pred_model_1 = model_1.predict(X)\n",
        "y_pred_model_2 = model_2.predict([X, placeholder_labels])\n",
        "\n",
        "# Combine predictions from both models as features\n",
        "X_stacked = np.hstack((y_pred_model_1, y_pred_model_2))\n",
        "\n",
        "# Train a simple stacking model (you can use any other algorithm as well)\n",
        "stacking_model = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
        "stacking_model.fit(X_stacked, y)\n",
        "\n",
        "# Load new molecules and preprocess them\n",
        "new_smiles = ['COC1=C(C=C(C=C1)C(=O)O)O']  # Example new molecule\n",
        "X_new = np.array([list(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smi), 2)) for smi in new_smiles])\n",
        "\n",
        "# Make predictions for the new molecules using both models\n",
        "y_pred_model_1_new = model_1.predict(X_new)\n",
        "y_pred_model_2_new = model_2.predict([X_new, np.zeros((len(X_new), 1))])  # Placeholder labels for new molecules\n",
        "\n",
        "# Combine predictions from both models as features for new molecules\n",
        "X_new_stacked = np.hstack((y_pred_model_1_new, y_pred_model_2_new))\n",
        "\n",
        "# Make predictions using the stacking model\n",
        "y_pred_new = stacking_model.predict(X_new_stacked)\n",
        "\n",
        "# Print the predicted binding affinity for the new molecules\n",
        "print(\"Predicted binding affinity for new molecules:\", y_pred_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J9VOOa9ufnB",
        "outputId": "9f93885a-d7df-48a5-b194-3e17f5e6c417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 3s 13ms/step\n",
            "36/36 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Predicted binding affinity for new molecules: [-3.547017]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from keras.models import load_model\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(_DATA)\n",
        "df = df.rename(columns={'Compound ID': 'id', 'ESOL predicted log solubility in mols per litre': 'binding_affinity'})\n",
        "df = df[['id', 'smiles', 'binding_affinity']]\n",
        "df = df.dropna()\n",
        "\n",
        "# Extract features X and target variable y\n",
        "X = [Chem.MolFromSmiles(smiles) for smiles in df['smiles']]\n",
        "X = np.array([list(AllChem.GetMorganFingerprintAsBitVect(mol, 2)) for mol in X])\n",
        "y = df['binding_affinity']\n",
        "\n",
        "# Load models\n",
        "model_1 = load_model('saved_model/ann_model_1.h5')\n",
        "model_2 = load_model('saved_model/cvae_model_1.h5')\n",
        "\n",
        "# Generate placeholder labels for the entire dataset\n",
        "num_samples = len(X)\n",
        "placeholder_labels = np.zeros((num_samples, 1))  # Assuming one class label\n",
        "\n",
        "# Predictions for the entire dataset using both models\n",
        "y_pred_model_1 = model_1.predict(X)\n",
        "y_pred_model_2 = model_2.predict([X, placeholder_labels])\n",
        "\n",
        "# Combine predictions from both models as features\n",
        "X_stacked = np.hstack((y_pred_model_1, y_pred_model_2))\n",
        "\n",
        "# Ensemble Method 1: Gradient Boosting\n",
        "gradient_boosting_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gradient_boosting_model.fit(X_stacked, y)\n",
        "\n",
        "# Ensemble Method 2: XGBoost\n",
        "xgboost_model = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
        "xgboost_model.fit(X_stacked, y)\n",
        "\n",
        "# Load new molecules and preprocess them\n",
        "new_smiles = ['COC1=C(C=C(C=C1)C(=O)O)O']  # Example new molecule\n",
        "X_new = np.array([list(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smi), 2)) for smi in new_smiles])\n",
        "\n",
        "# Make predictions for the new molecules using both models\n",
        "y_pred_model_1_new = model_1.predict(X_new)\n",
        "y_pred_model_2_new = model_2.predict([X_new, np.zeros((len(X_new), 1))])  # Placeholder labels for new molecules\n",
        "\n",
        "# Combine predictions from both models as features for new molecules\n",
        "X_new_stacked = np.hstack((y_pred_model_1_new, y_pred_model_2_new))\n",
        "\n",
        "# Make predictions using the ensemble models\n",
        "y_pred_new_gb = gradient_boosting_model.predict(X_new_stacked)\n",
        "y_pred_new_xgb = xgboost_model.predict(X_new_stacked)\n",
        "\n",
        "# Print the predicted binding affinity for the new molecules using Gradient Boosting\n",
        "print(\"Predicted binding affinity for new molecules (Gradient Boosting):\", y_pred_new_gb)\n",
        "\n",
        "# Print the predicted binding affinity for the new molecules using XGBoost\n",
        "print(\"Predicted binding affinity for new molecules (XGBoost):\", y_pred_new_xgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dHkCoTG-b4t",
        "outputId": "d78195e6-473d-441e-ac62-7449c39b0ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 5s 14ms/step\n",
            "36/36 [==============================] - 1s 10ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Predicted binding affinity for new molecules (Gradient Boosting): [-3.61350326]\n",
            "Predicted binding affinity for new molecules (XGBoost): [-3.3443282]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AHhUHiEBE_CP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}